{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81O3HLrz9-A5"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the spectral reflectance and soil property data\n",
        "def load_data(spectral_path, soil_properties_path):\n",
        "    spectral_data = pd.read_csv(spectral_path)\n",
        "    soil_data = pd.read_csv(soil_properties_path)\n",
        "    # Merge datasets on the ID column\n",
        "    merged_data = pd.merge(spectral_data, soil_data, on='ID', how='inner')\n",
        "    return merged_data\n"
      ],
      "metadata": {
        "id": "Tla0YUiO-Ec3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Apply PCA to select informative bands\n",
        "def apply_pca(data, n_components):\n",
        "    pca = PCA(n_components=n_components)\n",
        "    transformed_data = pca.fit_transform(data)\n",
        "    return transformed_data, pca\n",
        "\n"
      ],
      "metadata": {
        "id": "OFf9FlFR-Gom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Train the ANN model\n",
        "def train_ann(X_train, y_train):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)  # Output layer with 1 neuron for regression\n",
        "    ])\n",
        "    opt = Adam(learning_rate== 0.028)\n",
        "    model.compile(optimizer=opt, loss='mse')\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xVjeO8C--IZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Generate the equation from the trained ANN model\n",
        "def generate_equation(model):\n",
        "    weights = model.get_weights()\n",
        "    equation = \"\"\n",
        "    for layer_idx, (w, b) in enumerate(zip(weights[0::2], weights[1::2])):\n",
        "        equation += f\"Layer {layer_idx + 1}: Weights = {w.shape}, Biases = {b.shape}\\n\"\n",
        "    return equation\n",
        "\n",
        "# Step 5: Validate the generated equation on both LUCAS-2009 and AFSIS dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "WWiiXSoR-OTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    # File paths (update these paths to your file locations)\n",
        "    spectral_path = \"spc.csv\"\n",
        "    soil_properties_path = \"soil_data.csv\"\n",
        "\n",
        "    # Load and preprocess data\n",
        "    data = load_data(spectral_path, soil_properties_path)\n",
        "    spectral_columns = [col for col in data.columns if col.startswith('Band')]\n",
        "    X = data[spectral_columns]\n",
        "    y = data['Target']  # Replace 'Target' with the appropriate column name\n",
        "\n",
        "    # Apply PCA to reduce spectral dimensions\n",
        "    X_pca, pca_model = apply_pca(X, n_components=n_components)\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train ANN model\n",
        "    ann_model = train_ann(X_train, y_train)\n",
        "\n",
        "    # Generate the equation\n",
        "    equation = generate_equation(ann_model)\n",
        "    print(\"Generated Equation:\\n\", equation)\n",
        "\n",
        "    # Validate the equation using various evaluation metrics R2, RMSE, MAE and RPD"
      ],
      "metadata": {
        "id": "VZqZnoJI_EHY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}